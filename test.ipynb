{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os, lib\n",
    "from dotenv import load_dotenv\n",
    "import typing\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code snippet reads data from Excel files and processes it. It collects system reliability data, dates, and a DataFrame containing specific columns.\n",
    "\n",
    "Explanation:\n",
    "1. The code initializes three empty lists: `sys`, `dat`, and `df`.\n",
    "2. It searches for Excel files recursively in the current working directory.\n",
    "3. For each file:\n",
    "   a. Attempts to read data from the sheet named \"System Reliability Data\" using the openpyxl engine.\n",
    "   b. Reads additional data from the same sheet, skipping the first 8 rows.\n",
    "   c. Appends values from specific columns to the `sys` and `dat` lists.\n",
    "   d. Extracts a DataFrame containing specific columns from the remaining data and appends it to the `df` list.\n",
    "4. Any exceptions encountered during file processing are caught and ignored.\n",
    "\n",
    "Note:\n",
    "- This code assumes that the Excel files contain sheets named \"System Reliability Data.\"\n",
    "- Adjust the sheet names and column indices as needed for your specific data.\n",
    "\"\"\"\n",
    "\n",
    "sys, dat, df = [], [], []\n",
    "\n",
    "for file in glob.glob(os.path.join(os.getcwd(), \"**\", \"*.xlsx\"), recursive=True):\n",
    "    try:\n",
    "        a = pd.read_excel(file, sheet_name=\"System Reliability Data\", engine='openpyxl')\n",
    "        b = pd.read_excel(file, sheet_name=\"System Reliability Data\", engine='openpyxl', skiprows=8)\n",
    "        sys.append(a[\"Unnamed: 2\"][1])\n",
    "        dat.append(a[\"Unnamed: 2\"][2])\n",
    "        df.append(pd.DataFrame(b.iloc[:,17:-1].iloc[1]).T)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code snippet concatenates and processes data from a DataFrame. It assigns specific columns and sorts the DataFrame by date.\n",
    "\n",
    "Explanation:\n",
    "1. The code concatenates DataFrames contained in the list `df`.\n",
    "2. Two new columns are created in the resulting DataFrame: \"Date\" and \"System.\"\n",
    "3. Duplicate rows based on the \"Date\" column are removed.\n",
    "4. The \"Date\" column is set as the index of the DataFrame.\n",
    "5. The DataFrame is sorted in ascending order based on the date.\n",
    "\n",
    "Note:\n",
    "- Adjust column names and operations according to your specific data.\n",
    "\"\"\"\n",
    "\n",
    "raw_data: pd.DataFrame = pd.concat([df[j] for j in range(len(df))])\n",
    "raw_data[\"Date\"], raw_data[\"System\"] = dat, sys\n",
    "raw_data.index = raw_data[\"Date\"]\n",
    "data = raw_data.drop_duplicates().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"System\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code snippet filters a DataFrame based on specific system names. It creates a dictionary of desired system names and then filters the data accordingly.\n",
    "\n",
    "Explanation:\n",
    "1. The dictionary `desired_systems` maps system IDs to their corresponding names.\n",
    "2. The DataFrame `filtered_by_systems` is created by filtering rows where the \"System\" column value matches any of the desired system names.\n",
    "\n",
    "Note:\n",
    "- Adjust the system names and column names according to your specific data.\n",
    "\"\"\"\n",
    "\n",
    "desired_systems: typing.Dict[int, str] = {\n",
    "    1: \"Consumers Energy Co.\",\n",
    "    2: \"DTE Energy Co.\",\n",
    "    3: \"Indiana Michigan Power Co.\"\n",
    "}\n",
    "\n",
    "filtered_df: pd.DataFrame = data[(data[\"System\"]).isin(desired_systems.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields: typing.Dict[int, str] = {\n",
    "    1: \"Total Customer outages\",\n",
    "    2: \"Total number of outages causes by equipment failure\",\n",
    "    3: \"Total number of outages caused by lightning\",\n",
    "    4: \"Total number of planned and forced outages\",\n",
    "    5: \"Total number of outages caused by transmission or generation failure\",\n",
    "    6: \"Total number of outages caused by an act of the public at large\",\n",
    "    7: \"Total number of outages caused by trees\",\n",
    "    8: \"Total number of outage caused by weather\",\n",
    "    9: \"Total number of outages caued by animal interference\",\n",
    "    10: \"Total number of outages caused by unknonwn causes\",\n",
    "    11: \"Total number of outages caused by other causes\",\n",
    "    12: \"System Average Interruption Duration Index\", # ! SAIDI\n",
    "    13: \"System Average Interruption Frequency Index\", # ! SAIFI\n",
    "    14: \"Customer Average Interruption Duration Index (contribution to total CAIDI)\", # ! CAIDI\n",
    "    15: \"Average Service Availability Index\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code snippet visualizes a specific reliability index for different energy systems. It normalizes the data and plots it for each system.\n",
    "\n",
    "Explanation:\n",
    "1. The dictionary `fields` maps field IDs to their corresponding descriptions.\n",
    "2. The variable `field_to_analyze` is set to the description of the reliability index to be analyzed (e.g., SAIFI).\n",
    "3. A plot is created for each energy system, showing the normalized values of the specified reliability index.\n",
    "4. The y-axis represents the normalized index values (scaled to a maximum of 1).\n",
    "\n",
    "Note:\n",
    "- Adjust the field descriptions and column names according to your specific data.\n",
    "\"\"\"\n",
    "\n",
    "field_to_analyze: str = fields.get(11)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in filtered_df[\"System\"].value_counts().index:\n",
    "    (filtered_df[filtered_df[\"System\"] == i][field_to_analyze] / (filtered_df[filtered_df[\"System\"] == i][field_to_analyze].max() or 1)).plot(label=i)\n",
    "    plt.legend(ncol=3)\n",
    "    plt.title(label=field_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_data = pd.read_csv(os.getenv('FILE_PATH_OMNI'), delimiter=\" +\", names=range(55), engine=\"python\")\n",
    "except:\n",
    "    print(\"<Exception> OMNI File required\")\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code snippet filters and processes data from a DataFrame. It selects specific columns based on their indices and restricts the data to a specific date range.\n",
    "\n",
    "Explanation:\n",
    "1. The DataFrame `raw_data` contains columns with indices 0, 1, 2, 38, 39, 40, 49, 50, 22, 23, 24, 27, 28, and 8.\n",
    "2. The minimum and maximum dates from the DataFrame `filtered_df` are determined.\n",
    "3. The years corresponding to these dates are extracted using `pd.Timestamp`.\n",
    "4. The data is filtered to include only rows where the year (column 0) falls within the specified date range.\n",
    "5. Column names are assigned to the processed data for better readability.\n",
    "\n",
    "Note:\n",
    "- Adjust column indices and date range according to your specific data.\n",
    "\"\"\"\n",
    "\n",
    "data = raw_data[[0, 1, 2, 38, 39, 40, 49, 50, 22, 23, 24, 27, 28, 8]]\n",
    "min_date, max_date = filtered_df.index.min(), filtered_df.index.max()\n",
    "min_date_year, max_date_year = pd.Timestamp(min_date).year, pd.Timestamp(max_date).year\n",
    "data = data[(data[0] >= min_date_year) & (data[0] <= max_date_year)]\n",
    "\n",
    "data.columns = [\n",
    "    \"Year\", # \n",
    "    \"DecimalYear\", #\n",
    "    \"Hour\", #\n",
    "    \"Kp\", #\n",
    "    \"R\", #\n",
    "    \"DST\", #\n",
    "    \"Ap\", #\n",
    "    \"F10.7\", #\n",
    "    \"Proton temperature\", #\n",
    "    \"Proton density\", #\n",
    "    \"Plasma speed\", #\n",
    "    \"Alpha/Proton ratio\", #\n",
    "    \"Flow Pressure\", #\n",
    "    \"Field Magnitude Average |B|\" #\n",
    "]\n",
    "\n",
    "data.index = pd.date_range(str(min_date_year), str(max_date_year + 1), freq=\"60min\")[:-1]\n",
    "\n",
    "data = data[[\"Kp\", \"R\", \"DST\", \"Ap\", \"F10.7\", \"Proton temperature\", \"Proton density\", \"Plasma speed\", \"Alpha/Proton ratio\", \"Flow Pressure\", \"Field Magnitude Average |B|\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explanation:\n",
    "1. The DataFrame `data` contains columns that need cleaning.\n",
    "2. We create a list of column names to process.\n",
    "3. For each column, we replace specific values with NaN using `np.where`.\n",
    "\n",
    "Note:\n",
    "- Adjust column names and replacement values according to your specific data.\n",
    "\"\"\"\n",
    "\n",
    "columns_to_clean = [\n",
    "    \"F10.7\",\n",
    "    \"Kp\",\n",
    "    \"R\",\n",
    "    \"DST\",\n",
    "    \"Ap\",\n",
    "    \"Proton temperature\",\n",
    "    \"Proton density\",\n",
    "    \"Plasma speed\",\n",
    "    \"Alpha/Proton ratio\",\n",
    "    \"Flow Pressure\",\n",
    "    \"Field Magnitude Average |B|\"\n",
    "]\n",
    "\n",
    "for col in columns_to_clean:\n",
    "    data[col] = np.where(data[col] == 999.9, np.nan, data[col])\n",
    "    data[col] = np.where(data[col] == 99, np.nan, data[col])\n",
    "    data[col] = np.where(data[col] == 999, np.nan, data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.index >= str(min_date_year))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns(df: pd.DataFrame, new_columns: typing.Any) -> pd.DataFrame:\n",
    "    df[new_columns] = np.zeros((len(df), len(new_columns)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = data.copy()\n",
    "new_columns_kp: typing.List = ['G0', 'G1 ', 'G2', 'G3', 'G4', 'G5']\n",
    "df = create_columns(df=df, new_columns=new_columns_kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions: typing.Dict[str, pd.Series] = {\n",
    "    'G0': data['Kp'].le(43),\n",
    "    'G1': data['Kp'].between(46, 54),\n",
    "    'G2': data['Kp'].between(56, 64),\n",
    "    'G3': data['Kp'].between(66, 74),\n",
    "    'G4': data['Kp'].between(76, 88),\n",
    "    'G5': data['Kp'].ge(90)\n",
    "}\n",
    "\n",
    "for G, condition in conditions.items():\n",
    "    df[G] = condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_kp(df: pd.DataFrame, lvl, closed: bool = None) -> pd.DataFrame:\n",
    "    df_resampled_kp: pd.DataFrame = df.resample(rule=lvl, closed=closed).agg({\n",
    "        'Kp': 'max',\n",
    "        'R': 'mean',\n",
    "        'F10.7': 'mean',\n",
    "        'Proton temperature': 'mean',\n",
    "        'Proton density': 'mean',\n",
    "        'Plasma speed': 'mean',\n",
    "        'Alpha/Proton ratio': 'mean',\n",
    "        'Flow Pressure': 'mean',\n",
    "        'Field Magnitude Average |B|': 'mean',\n",
    "        'G1': 'sum',\n",
    "        'G1': 'sum',\n",
    "        'G2': 'sum',\n",
    "        'G3': 'sum',\n",
    "        'G4': 'sum',\n",
    "        'G5': 'sum'\n",
    "    })\n",
    "\n",
    "    df_resampled_kp['Total ST'] = df_resampled_kp[['G1', 'G2', 'G3', 'G4', 'G5']].sum(axis=1)\n",
    "    return df_resampled_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq: str = \"ME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resample_kp: pd.DataFrame = resample_kp(df, freq)\n",
    "df_resample_kp['Solar Cycle'] = pd.cut(df_resample_kp.index, \n",
    "                                        bins=[\n",
    "                                            pd.to_datetime('1964-10-01'),\n",
    "                                            pd.to_datetime('1976-03-01'),\n",
    "                                            pd.to_datetime('1986-09-01'),\n",
    "                                            pd.to_datetime(\"1996-08-01\"), \n",
    "                                            pd.to_datetime(\"2008-12-31\"),\n",
    "                                            pd.to_datetime(\"2019-12-31\"), \n",
    "                                            pd.to_datetime(\"2100-01-01\")\n",
    "                                        ],\n",
    "                                        labels=[20, 21, 22, 23, 24, 25])\n",
    "\n",
    "df_resample_kp = df_resample_kp.rename(columns={\"Kp\": \"Kp max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
